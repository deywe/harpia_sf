#!/usr/bin/env python3

# File: sphy_harpia_ghz_triple_shor_subprocess_v4_eng.py
# Purpose: GHZ Muxer with Triple Shor Integrated - Implements Zero-Time Reuse 
#          while using Subprocess for Symbiotic AI F_opt.
# üöÄ HARPIA V4 FIX: Shor success (0/1) conversion to binary string in CSV.
#          This fixes the inconsistent read error in the analyzer.

import warnings
warnings.filterwarnings("ignore")

import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['axes.unicode_minus'] = False

import os, csv, re, hashlib, random, subprocess, time
from datetime import datetime
from statistics import mean
import numpy as np
from tqdm import tqdm
# üí° ESSENTIAL: Multiprocessing for high speed and simultaneity
from concurrent.futures import ProcessPoolExecutor
from multiprocessing import Manager
import strawberryfields as sf
from strawberryfields.ops import Sgate, BSgate, MeasureFock

# üß† Imports the proprietary coherence stress injection model
# THIS IS THE KEY CHANGE: HOW the qubit is stressed is external.
from simbiotic_qubit_tracker_ai import generate_coherence_data

# ‚öôÔ∏è Configuration
LOG_DIR = "logs_triple_shor_subp"
IMG_DIR = "logs_triple_shor_subp" 
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(IMG_DIR, exist_ok=True) 
SAVE_BATCH = 120000 
BATCH_SIZE = 60000 

# üß† Shared multiplexed memory between processes
manager = Manager()
mux_history_buffer = manager.list()
history_lock = manager.Lock()
# Buffer to store all individual coherence signals for plotting
coherence_signals_buffer = manager.list()

# ‚û°Ô∏è Shor Constants (for symbolic probability)
SHOR_PROBS = {15: 0.38, 21: 0.28, 35: 0.18}
COHERENCE_THRESHOLD = 90.0

# üéõ Interactive Inputs 
def input_parameters():
    """
    Collects input parameters with isolated error handling to maintain
    valid values even if a subsequent input fails.
    """
    # Default values in case inputs fail
    n, f, noise, workers = 4, 10000, True, 4 

    try:
        n_input = input("üî¢ Number of qubits (max 13): ")
        n = min(int(n_input), 13)
    except ValueError:
        print("‚ùå Invalid qubits. Using n=4.")

    try:
        f_input = input("üîÅ Frames to simulate: ")
        f = int(f_input)
 
    except ValueError:
        # CORRECTED POINT: If the input fails, it keeps the valid values and only 
        # 'f' (frames) goes to default.
        print("‚ùå Invalid frames. Using f=10000.")

    noise_input = input("üå° Activate thermal noise (P=1.0 for max)? (y/n): ").lower()
    noise = noise_input == 'y'

    try:
        workers_input = input("‚öôÔ∏è Number of threads/workers (4 or more): ")
     
        workers = int(workers_input)
    except ValueError:
        print("‚ùå Invalid workers. Using workers=4.")
        
    return n, f, noise, workers

# üåÄ Symbiotic multiplexer, used to simulate multiplexing and multicore and also introduces extra noise, 
# the AI senses the quantum signature of the noise generated by the muxer.
def optical_mux_preprocessor(H, S, C, I, T, memory_size=12, decay=0.85):
    with history_lock:
        current = np.array([H, S, C, I], dtype=np.float32)
        mux_history_buffer.append(current)
        if len(mux_history_buffer) > memory_size:
            mux_history_buffer.pop(0)

 
        weights = np.array([decay ** (len(mux_history_buffer) - 1 - i) for i in range(len(mux_history_buffer))])
        weights /= weights.sum()
        muxed = sum(w * x for w, x in zip(weights, mux_history_buffer))

    mH = muxed[0] * np.clip(1 + np.sin(T * 0.1), 0.9, 1.1)
    mS = muxed[1] + np.cos(muxed[2] * np.pi)
    mC = (muxed[2] + muxed[0] - muxed[1]) * 0.5
    mI = abs(mH - mS) * np.clip(np.sin(mC * 3), 0.7, 1.3)
   
    return float(mH), float(mS), float(mC), float(mI)

# Laser Resonance Simulator for Field Coupling 
def simulate_laser_resonance(t_frame, mH, mS, mC, mI):
    wow_vector = np.array([0.65, 0.4, 0.5, 0.8])
    current_vector = np.array([mH, mS, mC, mI])
    
    dot_product = np.dot(current_vector, wow_vector)
    norm_product = np.linalg.norm(current_vector) * np.linalg.norm(wow_vector)
    coherence_alignment = dot_product / norm_product if norm_product != 0 else 0
    
    if coherence_alignment > 0.995: 
     
        return coherence_alignment * 5.0 
    else:
        return 0.0

# External call for symbiotic boost (Meissner Core) - SUBPROCESS
def compute_F_opt_subprocess(H, S, C, I, T):
    """Executes the Meissner Core (sphy_simbiotic_entangle_ai) via subprocess."""
    try:
        # The 'timeout' instruction is essential to prevent deadlocks
        result = subprocess.run(
            ["./sphy_simbiotic_entangle_ai", str(H), str(S), str(C), str(I), str(T)],
         
            capture_output=True, text=True, check=True, timeout=0.5 
        )
        match = re.search(r"([-+]?\d*\.\d+|\d+)", result.stdout)
        return float(match.group(0)) if match else 0.0
    except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
        # Returns a base value if the subprocess fails or the file doesn't exist
        return 0.001 
    except Exception:
        return 0.001

def generate_sha256_from_frame(frame_id, result, coherence, uid):
    raw = f"{frame_id}_{result}_{coherence:.4f}_{uid}"
    return hashlib.sha256(raw.encode()).hexdigest()

# GHZ is valid if close to a binary chain "000" or "111" 
def is_quasi_ghz(sample, threshold=2):
    ideal_0 = '0' * len(sample)
    ideal_1 = '1' * len(sample)
    h0 = sum(a != b for a, b in zip(sample, ideal_0))
    h1 = sum(a != b for a, b in zip(sample, ideal_1))
    return min(h0, h1) <= threshold

# Basic photonic simulator + optional noise 
def simulate_ghz_state(n, cutoff, noise):
    prog = sf.Program(n)
    with prog.context as q:
      
        for i in range(n): sf.ops.Sgate(1.0)|q[i]
        for i in range(n - 1): sf.ops.BSgate(np.pi / 4, 0)|(q[0], q[i+1])
        if noise:
            for i in range(n): sf.ops.Sgate(np.random.normal(0, 1.0))|q[i]
        sf.ops.MeasureFock()|q
    try:
        result = sf.Engine("fock", backend_options={"cutoff_dim": cutoff}).run(prog)
        return ''.join(map(str, result.samples[0]))
    except Exception:
        return "ERROR"

# Triple Shor Factoring Logic 
def is_factor_found(N, coherence, factor_N_previous=None):
    base_success_prob = SHOR_PROBS.get(N, 0)
    coherence_boost_factor = (coherence / 100) * 1.5 
    P_success = base_success_prob * coherence_boost_factor
    
    # Immediate Reuse Logic (HARPIA Advantage)
    if N != 15 and factor_N_previous == False:
         P_success *= 2.0 
         
    P_success = np.clip(P_success, 0.05, 0.95)
    
    success = random.random() < P_success
 
    
    return success

# üí° Shor simulation core
def simulate_frame_logic(fid, modes, cutoff, noise):
    coherence = COHERENCE_THRESHOLD
    result = simulate_ghz_state(modes, cutoff, noise)
    
    # ‚ùå Error Condition
    if result == "ERROR":
        empty_coherence_signals = [0.0] * modes
        return fid, "SIM_ERROR", *empty_coherence_signals, 0, 0, 0, 0, 0, 0, 0, 90.0, "REJECTED", False, "‚ùå", "SIM_ERROR", False, False, False

    # Individual coherence tracking for N QUBITS
    # üåü EXTERNAL MODULE CALL TO GET COHERENCE AND NOISE DATA
    H, S, C, I, coherence_signals = generate_coherence_data(modes, fid, coherence / 100)

    # Pre-processing and Field Modulation (MUX)
    mH, mS, mC, mI = optical_mux_preprocessor(H, S, C, I, fid)

    # Stability Boosts
    laser_boost = simulate_laser_resonance(fid, mH, mS, mC, mI)
    ai_boost = compute_F_opt_subprocess(mH, mS, mC, mI, fid)
    total_boost = ai_boost + laser_boost

    delta = total_boost * 0.7
    coherence = min(coherence + delta, 100.0) 

    # ‚öõÔ∏è TRIPLE SHOR INTEGRATION 
 
    success_N15 = is_factor_found(15, coherence)
    success_N21 = is_factor_found(21, coherence, factor_N_previous=success_N15)
    success_N35 = is_factor_found(35, coherence, factor_N_previous=success_N21) 
    
    valid_ghz = is_quasi_ghz(result) and delta > 0.3
    valid_shor = success_N15 or success_N21 or success_n35
    
    valid = valid_ghz and valid_shor
    
    uid = hashlib.sha256(f"{result}_{fid}_{total_boost}".encode()).hexdigest()[:12] if valid else "REJECTED"
    sha = generate_sha256_from_frame(fid, result, coherence, uid)
    
    # FINAL RETURN: Includes individual coherence signals (N_qubits extra columns)
    return fid, result, *coherence_signals, mH, mS, mC, mI, ai_boost, laser_boost, total_boost, coherence, uid, valid, "‚úÖ" if valid else "‚ùå", sha, success_N15, success_N21, success_N35


# üöÄ Simulation worker
def simulate_frame_worker(fid, modes, cutoff, noise):
    try:
        return simulate_frame_logic(fid, modes, cutoff, noise)
    except Exception as e:
        empty_coherence_signals = [0.0] * modes
        return fid, "WORKER_ERROR", *empty_coherence_signals, 0, 0, 0, 0, 0, 0, 0, 90.0, "REJECTED", False, "‚ùå", "WORKER_ERROR", False, False, False

# üéõ Helper function to map simulations
def worker_wrapper(fid, modes, cutoff, noise):
    return simulate_frame_worker(fid, modes, cutoff, noise)

# üìà FUNCTION TO GENERATE INDIVIDUAL AND AVERAGE TRACKING PLOT (SPECTRAL STYLE)
def generate_coherence_plot(evolution, coherence_signals_buffer, modes, csv_path, duration):
    """
    Generates a "Vibrational Spectral" style plot comparing the coherence 
    of each qubit with the Mean Coherence (HARPIA Field).
    """
    
    base_name = os.path.basename(csv_path).replace(".csv", "_tracking.png")
    img_file = os.path.join(IMG_DIR, base_name)
    
    if not evolution or not coherence_signals_buffer:
        print("‚ö†Ô∏è Insufficient data to generate plot.")
        return
    
    # 1. Configure dark style and figure
    plt.style.use('dark_background')
    fig, ax = plt.subplots(figsize=(14, 8))
    
    frames = len(evolution)
    
    # Convert the shared list buffer to a numpy array for plotting
    # Ensures the buffer is correctly emptied for the array
    individual_signals_matrix = np.array(list(coherence_signals_buffer)).T
    
    # Create a vibrant colormap (e.g., 'hsv')
    cmap = plt.cm.get_cmap('hsv')
    
    # 2. Plotting Individual Signals (Qubits)
    for i in range(modes):
        # Dynamic color based on qubit index (vibrant colors from the colormap)
        color = cmap(i / modes) 
        
        # Plot each qubit with low opacity to create the "spectrum"
        ax.plot(individual_signals_matrix[i], 
                alpha=0.35,  # High transparency
                linewidth=1.0, 
                color=color, 
         
                label=f"Qubit {i+1}") 
        
    # 3. Plotting Aggregate Coherence Evolution (Mean)
    mean_stability = mean(evolution)
    
    # Thick, central white line ("Entanglement Medium" effect)
    ax.plot(evolution, 
            color='white', 
            linewidth=3.0, 
            linestyle='-', 
    
            label=f"HARPIA Field Mean Coherence ({modes} Qubits)")
    
    # 4. Reference Lines and Aesthetics
    
    # Mean Line (Dotted)
    ax.axhline(y=mean_stability, color='cyan', linestyle=':', linewidth=0.8, alpha=0.7)
    
    ax.set_xlabel(f"Simulation Frame (Total: {frames:,})", color='lightgray')
    ax.set_ylabel("Coherence/Amplitude (Simulated)", color='lightgray')
    ax.set_ylim(0, 1.1) 
    
    ax.set_title(f"Qubit by Qubit Coherence Spectral Visualization", color='white', fontsize=18)
    
    # Legend (NOW SHOWS ALL INDIVIDUAL QUBITS + HARPIA MEAN)
    # Define the number of columns dynamically (max 3) for better fit
    num_legend_cols = min(3, modes + 1)
    
    ax.legend(loc='upper right', frameon=False, ncol=num_legend_cols, fontsize='small') # Small font size to fit more labels

    # Grids (fine and discrete)
    ax.grid(True, linestyle='--', alpha=0.2)

    fig.suptitle(f"HARPIA Fault Tolerance Analysis - Time: {duration:.2f}s", color='cyan', fontsize=12)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(img_file, dpi=150) # Save with high resolution
    
    print(f"üìä Qubit Tracking Plot saved to: {img_file}")
    plt.show() # Display the new image
    plt.close(fig) # Close the figure to free up memory


# üéõ Main execution with batch processing
def run_simulation(modes, total=1_000_000, thermal_noise=False, thread_workers=4):
    cutoff = 2 if modes < 10 else 1
   
    now = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_path = f"{LOG_DIR}/shor_muxed_triple_subp_{modes}q_{now}.csv"

    step_buffer = []
    evolution = []
    
    # Shor Counters
    success_n15, success_n21, success_n35 = 0, 0, 0
    rejections_n15, rejections_n21 = 0, 0
    reuse_success_n21, reuse_success_n35 = 0, 0

    # DYNAMIC CALCULATION OF CSV HEADERS
    qubit_headers = [f"Qubit_{i+1}_Coh" for i in range(modes)]
    main_headers = ["Frame", "Result"]
    mux_boost_headers = ["H'", "S'", "C'", "I'", "AI Boost", "Laser Boost", "Total Boost", 
    "Coherence", "UID", "Valid", "Symbol", "SHA256", "Shor N15", "Shor N21", "Shor N35"]
    headers = main_headers + qubit_headers + mux_boost_headers

    with open(csv_path, "w", newline="") as f:
        csv.writer(f).writerow(headers)

    print("="*60)
    print(f"üß¨ GHZ + MUX + TRIPLE SHOR (Subprocess) | Modes: {modes} | Frames: {total:,}")
    print(f"üß† CONCEPT: Field Stability vs. Logic Reuse")
    print("="*60)

    start = time.time()
    pbar = tqdm(total=total, desc="üîÅ Simulating...")

    for i in range(0, total, BATCH_SIZE):
        batch = range(i + 1, min(i + BATCH_SIZE + 1, total + 1))
        
        with ProcessPoolExecutor(max_workers=thread_workers) as executor:
            map_args = [(fid, modes, cutoff, thermal_noise) 
            for fid in batch]
            for result_tuple in executor.map(worker_wrapper, *zip(*map_args)):
                try:
                    # Dynamic unpacking
                    fid, result = result_tuple[0], result_tuple[1]
                   
                    coherence_signals = result_tuple[2 : 2 + modes]
                    (mH, mS, mC, mI, ai_boost, laser_boost, total_boost, coh, uid, valid, symbol, sha, 
                     s15, s21, s35) = result_tuple[2 + modes:]

                    # ADD TO SHARED PLOTTING BUFFER
        
                    coherence_signals_buffer.append(list(coherence_signals))
                    
                    # Update Shor counters
                    success_n15 += int(s15)
                    success_n21 += int(s21) 
 
                    success_n35 += int(s35) 

                    if not s15: 
                        rejections_n15 += 1
                        if s21: reuse_success_n21 += 1 
                    
                    if not s21:
                        rejections_n21 += 1
                        if s35: reuse_success_n35 += 1
   
                      
                    # DYNAMIC CONSTRUCTION OF CSV ROW
                    coherence_signals_rounded = [round(c, 4) for c in coherence_signals]
                    
      
                    row_data = [fid, result] + coherence_signals_rounded + [
                        round(mH, 4), round(mS, 4), round(mC, 4),
                        round(mI, 4), round(ai_boost, 4), round(laser_boost, 4), 
                    
                        round(total_boost, 4), round(coh, 4), uid, symbol, sha, 
                        # üåü HARPIA V4 FIX: Ensures 0/1 is written as a binary STRING.
                        str(int(s15)), str(int(s21)), str(int(s35)) 
                    ]
                    
                    step_buffer.append(row_data)
   
                    evolution.append(coh)

                    # Batch saving logic
                    if len(step_buffer) >= SAVE_BATCH:
                        with open(csv_path, "a", newline="") as f:
      
                            csv.writer(f).writerows(step_buffer)
                        step_buffer.clear()

                except Exception as e:
                    # The Worker error (which returns "WORKER_ERROR") is handled here so it doesn't stop the loop.
                    pass 
              
                pbar.update(1)

    # Final flush
    if step_buffer:
        with open(csv_path, "a", newline="") as f:
            csv.writer(f).writerows(step_buffer)

    pbar.close()
    duration = time.time() - start
    
    # FINAL CALCULATIONS
    total_success_shor = success_n15 + reuse_success_n21 + reuse_success_n35
    total_utility_rate = (total_success_shor / total) * 100
    
    # FINAL SUMMARY
    print("\n" + "="*60)
    
    print("HARPIA TRIPLE SHOR SUMMARY")
    print("="*60)
    print(f"‚è± Total simulation time: {duration:.2f}s")
    print(f"üî¢ Frames simulated: {total:,}")
    
    print("\n| **HARPIA UTILITY SUMMARY** |")
    print(f"| 1. Success (N=15): {success_n15}/{total} ({(success_n15/total)*100:.2f}%)")
    print(f"| 2. Rejections (N=15): {rejections_n15}/{total}")
    reuse_n21_rate = (reuse_success_n21/rejections_n15)*100 if rejections_n15 > 0 else 0.00
    print(f"| 3. Reuse Success (N=21): {reuse_success_n21}/{rejections_n15} ({reuse_n21_rate:.2f}%)")
    print(f"| 4. Rejections (N=21, rest.): {rejections_n21}/{total}")
    reuse_n35_rate = (reuse_success_n35/rejections_n21)*100 if rejections_n21 > 0 else 0.00
    print(f"| 5. Reuse Success (N=35): {reuse_success_n35}/{rejections_n21} ({reuse_n35_rate:.2f}%)")
    print(f"| **TOTAL UTILITY (N1, N2 or N3):** {total_success_shor}/{total} | **{total_utility_rate:.2f}%**")
    
    print(f"\n<<< **HARPIA ADVANTAGE:** {reuse_success_n21 + reuse_success_n35} factors of N=21/N=35 found by Immediate Reuse.")
    
    # Calculation of stability indices
    if evolution:
        mean_stability = mean(evolution)
        stability_variance = np.var(evolution)
        print(f"\nüìä Mean Stability Index: {mean_stability:.6f}")
        print(f"üìä Stability Variance Index: {stability_variance:.6f}")
        
    print(f"üìÅ CSV saved: {csv_path}")

    # CALL TO SPECTRAL STYLE PLOT GENERATOR
    
    generate_coherence_plot(evolution, coherence_signals_buffer, modes, csv_path, duration)

# üöÄ Direct execution
if __name__ == "__main__":
    modes, frames, noise, workers = input_parameters()
    run_simulation(modes, frames, thermal_noise=noise, thread_workers=workers)